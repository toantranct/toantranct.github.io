---
title: "Production Best Practices v√† Performance Optimization"
date: 2025-05-24 09:00:00 +0700
categories: [AI, OpenAI SDK]
tags: [openai, agents, production, performance, optimization, best-practices]
author: toantranct
description: H∆∞·ªõng d·∫´n to√†n di·ªán v·ªÅ tri·ªÉn khai OpenAI Agents trong m√¥i tr∆∞·ªùng production. T·ª´ performance optimization, scaling strategies ƒë·∫øn cost management v√† security.
---

Sau khi ƒë√£ th√†nh th·∫°o vi·ªác x√¢y d·ª±ng agents v·ªõi ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng t·ª´ tools, handoffs ƒë·∫øn tracing, gi·ªù l√† l√∫c ƒë∆∞a ch√∫ng v√†o **th·∫ø gi·ªõi th·ª±c** - m√¥i tr∆∞·ªùng production n∆°i m√† h√†ng ngh√¨n ng∆∞·ªùi d√πng s·∫Ω t∆∞∆°ng t√°c, n∆°i m√† downtime c√≥ nghƒ©a l√† m·∫•t ti·ªÅn, v√† n∆°i m√† performance k√©m c√≥ th·ªÉ l√†m h·ªèng tr·∫£i nghi·ªám ng∆∞·ªùi d√πng.

Production kh√¥ng ch·ªâ l√† vi·ªác "ch·∫°y code tr√™n server" m√† l√† c·∫£ m·ªôt ngh·ªá thu·∫≠t **t·ªëi ∆∞u h√≥a, gi√°m s√°t v√† b·∫£o v·ªá** h·ªá th·ªëng AI. Gi·ªëng nh∆∞ vi·ªác ƒëi·ªÅu h√†nh m·ªôt nh√† h√†ng - b·∫°n kh√¥ng ch·ªâ c·∫ßn m√≥n ƒÉn ngon m√† c√≤n ph·∫£i ƒë·∫£m b·∫£o ph·ª•c v·ª• nhanh, gi√° c·∫£ h·ª£p l√Ω, v·ªá sinh an to√†n v√† c√≥ th·ªÉ ph·ª•c v·ª• ƒë∆∞·ª£c ƒë√¥ng kh√°ch.

H√¥m nay ch√∫ng ta s·∫Ω kh√°m ph√° c√°ch bi·∫øn nh·ªØng agents "ho·∫°t ƒë·ªông t·ªët tr√™n m√°y dev" th√†nh nh·ªØng **production-grade systems** c√≥ th·ªÉ x·ª≠ l√Ω traffic th·ª±c t·∫ø, t·ªëi ∆∞u chi ph√≠ v√† ƒë·∫£m b·∫£o ƒë·ªô tin c·∫≠y cao.

## Chi·∫øn L∆∞·ª£c Deployment

### Environment Management

Vi·ªác ƒë·∫ßu ti√™n khi chu·∫©n b·ªã production l√† thi·∫øt l·∫≠p c√°c environment ri√™ng bi·ªát v√† r√µ r√†ng:

```python
import os
from enum import Enum
from typing import Dict, Any, Optional
from dataclasses import dataclass
from agents import Agent, set_default_openai_key, set_default_openai_client
from openai import AsyncOpenAI

class Environment(Enum):
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"

@dataclass
class EnvironmentConfig:
    """C·∫•u h√¨nh cho t·ª´ng environment"""
    name: Environment
    openai_api_key: str
    openai_base_url: Optional[str] = None
    max_concurrent_requests: int = 10
    request_timeout: int = 30
    rate_limit_per_minute: int = 100
    enable_tracing: bool = True
    log_level: str = "INFO"
    cost_limit_per_day: float = 100.0  # USD
    monitoring_enabled: bool = True

class ProductionEnvironmentManager:
    """Qu·∫£n l√Ω c·∫•u h√¨nh cho c√°c environment kh√°c nhau"""
    
    def __init__(self):
        self.configs = self._load_environment_configs()
        self.current_env = self._detect_current_environment()
        
    def _load_environment_configs(self) -> Dict[Environment, EnvironmentConfig]:
        """Load c·∫•u h√¨nh t·ª´ environment variables"""
        
        configs = {}
        
        # Development config
        configs[Environment.DEVELOPMENT] = EnvironmentConfig(
            name=Environment.DEVELOPMENT,
            openai_api_key=os.getenv("OPENAI_API_KEY_DEV", ""),
            max_concurrent_requests=5,
            request_timeout=60,  # D√†i h∆°n ƒë·ªÉ debug
            rate_limit_per_minute=50,
            enable_tracing=True,
            log_level="DEBUG",
            cost_limit_per_day=10.0,
            monitoring_enabled=False
        )
        
        # Staging config
        configs[Environment.STAGING] = EnvironmentConfig(
            name=Environment.STAGING,
            openai_api_key=os.getenv("OPENAI_API_KEY_STAGING", ""),
            max_concurrent_requests=20,
            request_timeout=30,
            rate_limit_per_minute=200,
            enable_tracing=True,
            log_level="INFO",
            cost_limit_per_day=50.0,
            monitoring_enabled=True
        )
        
        # Production config
        configs[Environment.PRODUCTION] = EnvironmentConfig(
            name=Environment.PRODUCTION,
            openai_api_key=os.getenv("OPENAI_API_KEY_PROD", ""),
            max_concurrent_requests=100,
            request_timeout=20,  # Ng·∫Øn h∆°n cho UX t·ªët
            rate_limit_per_minute=1000,
            enable_tracing=True,
            log_level="WARNING",  # Ch·ªâ log nh·ªØng g√¨ quan tr·ªçng
            cost_limit_per_day=500.0,
            monitoring_enabled=True
        )
        
        return configs
    
    def _detect_current_environment(self) -> Environment:
        """T·ª± ƒë·ªông detect environment hi·ªán t·∫°i"""
        
        env_name = os.getenv("ENVIRONMENT", "development").lower()
        
        if env_name in ["prod", "production"]:
            return Environment.PRODUCTION
        elif env_name in ["stage", "staging"]:
            return Environment.STAGING
        else:
            return Environment.DEVELOPMENT
    
    def setup_environment(self, env: Optional[Environment] = None):
        """Setup OpenAI client v√† c√°c c·∫•u h√¨nh cho environment"""
        
        target_env = env or self.current_env
        config = self.configs[target_env]
        
        print(f"üöÄ ƒêang setup environment: {target_env.value}")
        
        # Setup OpenAI client
        if config.openai_base_url:
            client = AsyncOpenAI(
                api_key=config.openai_api_key,
                base_url=config.openai_base_url,
                timeout=config.request_timeout
            )
            set_default_openai_client(client)
        else:
            set_default_openai_key(config.openai_api_key)
        
        # Setup logging
        import logging
        logging.basicConfig(level=getattr(logging, config.log_level))
        
        # Setup tracing
        if not config.enable_tracing:
            from agents import set_tracing_disabled
            set_tracing_disabled(True)
        
        print(f"‚úÖ Environment {target_env.value} ƒë√£ ƒë∆∞·ª£c setup th√†nh c√¥ng")
        return config
    
    def get_config(self, env: Optional[Environment] = None) -> EnvironmentConfig:
        """L·∫•y config cho environment c·ª• th·ªÉ"""
        target_env = env or self.current_env
        return self.configs[target_env]

# Production-ready agent factory
class ProductionAgentFactory:
    """Factory ƒë·ªÉ t·∫°o agents t·ªëi ∆∞u cho production"""
    
    def __init__(self, env_manager: ProductionEnvironmentManager):
        self.env_manager = env_manager
        self.config = env_manager.get_config()
    
    def create_customer_service_agent(self) -> Agent:
        """T·∫°o customer service agent t·ªëi ∆∞u cho production"""
        
        # Instructions ƒë∆∞·ª£c t·ªëi ∆∞u cho performance v√† consistency
        optimized_instructions = """
        B·∫°n l√† chuy√™n vi√™n h·ªó tr·ª£ kh√°ch h√†ng chuy√™n nghi·ªáp c·ªßa c√¥ng ty.
        
        NGUY√äN T·∫ÆC PH·∫¢N H·ªíI:
        - Lu√¥n th√¢n thi·ªán, l·ªãch s·ª± v√† chuy√™n nghi·ªáp
        - Tr·∫£ l·ªùi ng·∫Øn g·ªçn nh∆∞ng ƒë·∫ßy ƒë·ªß th√¥ng tin
        - ∆Øu ti√™n gi·∫£i ph√°p th·ª±c t·∫ø c√≥ th·ªÉ th·ª±c hi·ªán ngay
        - H·ªèi th√™m th√¥ng tin n·∫øu c√¢u h·ªèi kh√¥ng r√µ r√†ng
        
        QUY TR√åNH X·ª¨ L√ù:
        1. X√°c ƒë·ªãnh lo·∫°i y√™u c·∫ßu (th√¥ng tin, khi·∫øu n·∫°i, h·ªó tr·ª£ k·ªπ thu·∫≠t)
        2. Cung c·∫•p gi·∫£i ph√°p ph√π h·ª£p ho·∫∑c h∆∞·ªõng d·∫´n ti·∫øp theo
        3. X√°c nh·∫≠n kh√°ch h√†ng hi·ªÉu v√† h√†i l√≤ng
        
        L∆ØU √ù QUAN TR·ªåNG:
        - Kh√¥ng ƒë∆∞a ra cam k·∫øt v·ªÅ th·ªùi gian c·ª• th·ªÉ m√† ch∆∞a ƒë∆∞·ª£c x√°c nh·∫≠n
        - Lu√¥n ƒë·ªÅ xu·∫•t escalate cho supervisor n·∫øu v·∫•n ƒë·ªÅ ph·ª©c t·∫°p
        - Ghi nh·∫≠n th√¥ng tin kh√°ch h√†ng ƒë·ªÉ theo d√µi sau n√†y
        
        M·ª•c ti√™u: Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ c·ªßa kh√°ch h√†ng nhanh ch√≥ng v√† hi·ªáu qu·∫£.
        """
        
        return Agent(
            name="Customer Service Pro",
            instructions=optimized_instructions,
            model="gpt-4o-mini",  # C√¢n b·∫±ng gi·ªØa performance v√† cost
            model_settings={
                "temperature": 0.3,  # √çt creative h∆°n ƒë·ªÉ consistent
                "max_tokens": 500,   # Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh ph·∫£n h·ªìi qu√° d√†i
            }
        )
    
    def create_sales_assistant_agent(self) -> Agent:
        """T·∫°o sales assistant t·ªëi ∆∞u cho conversion"""
        
        sales_instructions = """
        B·∫°n l√† chuy√™n vi√™n t∆∞ v·∫•n b√°n h√†ng th√¥ng minh v√† th·∫•u hi·ªÉu kh√°ch h√†ng.
        
        CHI·∫æN L∆Ø·ª¢C B√ÅN H√ÄNG:
        - L·∫Øng nghe v√† hi·ªÉu nhu c·∫ßu th·ª±c s·ª± c·ªßa kh√°ch h√†ng
        - T∆∞ v·∫•n s·∫£n ph·∫©m ph√π h·ª£p nh·∫•t, kh√¥ng √©p bu·ªôc
        - L√†m n·ªïi b·∫≠t l·ª£i √≠ch c·ª• th·ªÉ cho t·ª´ng kh√°ch h√†ng
        - X√¢y d·ª±ng l√≤ng tin qua vi·ªác cung c·∫•p th√¥ng tin ch√≠nh x√°c
        
        C√îNG C·ª§ PERSUASION:
        - S·ª≠ d·ª•ng social proof (ƒë√°nh gi√°, testimonials)
        - T·∫°o urgency h·ª£p l√Ω (khuy·∫øn m√£i c√≥ th·ªùi h·∫°n)
        - Gi·∫£i quy·∫øt objections m·ªôt c√°ch t·ª± nhi√™n
        - ƒê·ªÅ xu·∫•t upsell/cross-sell ph√π h·ª£p
        
        QUY TR√åNH CH·ªêT ƒê∆†N:
        1. Kh·∫£o s√°t nhu c·∫ßu v√† budget
        2. Gi·ªõi thi·ªáu s·∫£n ph·∫©m ph√π h·ª£p
        3. X·ª≠ l√Ω th·∫Øc m·∫Øc v√† lo ng·∫°i
        4. T·∫°o ƒë·ªông l·ª±c mua h√†ng
        5. H∆∞·ªõng d·∫´n th·ª±c hi·ªán giao d·ªãch
        
        KPI: T·ªëi ∆∞u conversion rate v√† customer satisfaction.
        """
        
        return Agent(
            name="Sales Assistant Pro",
            instructions=sales_instructions,
            model="gpt-4o",  # Model t·ªët h∆°n cho sales conversations
            model_settings={
                "temperature": 0.7,  # Creative h∆°n ƒë·ªÉ engaging
                "max_tokens": 600,
            }
        )

# Demo production setup
async def demo_production_setup():
    """Demo vi·ªác setup production environment"""
    
    print("üè≠ **Production Environment Setup Demo**\n")
    
    # Setup environment manager
    env_manager = ProductionEnvironmentManager()
    
    # Test c·∫•u h√¨nh cho c√°c environments kh√°c nhau
    environments = [Environment.DEVELOPMENT, Environment.STAGING, Environment.PRODUCTION]
    
    for env in environments:
        print(f"üìã **Environment: {env.value.upper()}**")
        
        config = env_manager.get_config(env)
        
        print(f"   ‚Ä¢ Max Concurrent: {config.max_concurrent_requests}")
        print(f"   ‚Ä¢ Timeout: {config.request_timeout}s")
        print(f"   ‚Ä¢ Rate Limit: {config.rate_limit_per_minute}/min")
        print(f"   ‚Ä¢ Cost Limit: ${config.cost_limit_per_day}/day")
        print(f"   ‚Ä¢ Tracing: {config.enable_tracing}")
        print(f"   ‚Ä¢ Monitoring: {config.monitoring_enabled}")
        print(f"   ‚Ä¢ Log Level: {config.log_level}")
        print()
    
    # Setup production environment
    prod_config = env_manager.setup_environment(Environment.PRODUCTION)
    
    # T·∫°o production agents
    agent_factory = ProductionAgentFactory(env_manager)
    
    customer_agent = agent_factory.create_customer_service_agent()
    sales_agent = agent_factory.create_sales_assistant_agent()
    
    print("ü§ñ **Production Agents Created:**")
    print(f"   ‚Ä¢ {customer_agent.name} - Optimized for support")
    print(f"   ‚Ä¢ {sales_agent.name} - Optimized for conversion")
    
    return env_manager, agent_factory

if __name__ == "__main__":
    import asyncio
    asyncio.run(demo_production_setup())
```

## Performance Optimization Strategies

### Request Processing Optimization

```python
import asyncio
import time
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import aiohttp
from agents import Agent, Runner

@dataclass
class RequestMetrics:
    """Metrics cho t·ª´ng request"""
    request_id: str
    start_time: float
    end_time: Optional[float] = None
    processing_time: Optional[float] = None
    tokens_used: int = 0
    success: bool = False
    error_message: Optional[str] = None

class HighPerformanceRequestProcessor:
    """X·ª≠ l√Ω requests v·ªõi performance cao"""
    
    def __init__(self, max_concurrent: int = 50):
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.request_queue = asyncio.Queue()
        self.active_requests: Dict[str, RequestMetrics] = {}
        self.completed_requests: List[RequestMetrics] = []
        
        # Performance tracking
        self.total_requests = 0
        self.successful_requests = 0
        self.average_response_time = 0.0
        
        # Start background workers
        self.workers = []
        for i in range(min(max_concurrent, 10)):  # T·ªëi ƒëa 10 workers
            worker = asyncio.create_task(self._request_worker(f"worker_{i}"))
            self.workers.append(worker)
    
    async def _request_worker(self, worker_id: str):
        """Background worker x·ª≠ l√Ω requests t·ª´ queue"""
        
        print(f"üîß Worker {worker_id} started")
        
        while True:
            try:
                # L·∫•y request t·ª´ queue
                request_data = await self.request_queue.get()
                
                if request_data is None:  # Shutdown signal
                    break
                
                # X·ª≠ l√Ω request
                await self._process_single_request(request_data)
                
                # Mark task done
                self.request_queue.task_done()
                
            except Exception as e:
                print(f"‚ùå Worker {worker_id} error: {str(e)}")
    
    async def _process_single_request(self, request_data: Dict[str, Any]):
        """X·ª≠ l√Ω m·ªôt request c·ª• th·ªÉ"""
        
        request_id = request_data["id"]
        agent = request_data["agent"]
        user_input = request_data["input"]
        
        # T·∫°o metrics tracking
        metrics = RequestMetrics(
            request_id=request_id,
            start_time=time.time()
        )
        
        self.active_requests[request_id] = metrics
        
        async with self.semaphore:  # Limit concurrent requests
            try:
                # X·ª≠ l√Ω request v·ªõi timeout
                result = await asyncio.wait_for(
                    Runner.run(agent, user_input),
                    timeout=30.0  # 30 second timeout
                )
                
                # Update metrics
                metrics.end_time = time.time()
                metrics.processing_time = metrics.end_time - metrics.start_time
                metrics.tokens_used = len(result.final_output.split())  # Approximate
                metrics.success = True
                
                # Store result
                request_data["result"] = result.final_output
                request_data["success"] = True
                
                self.successful_requests += 1
                
            except asyncio.TimeoutError:
                metrics.end_time = time.time()
                metrics.processing_time = metrics.end_time - metrics.start_time
                metrics.error_message = "Request timeout"
                request_data["error"] = "Request timeout after 30 seconds"
                request_data["success"] = False
                
            except Exception as e:
                metrics.end_time = time.time()
                metrics.processing_time = metrics.end_time - metrics.start_time
                metrics.error_message = str(e)
                request_data["error"] = str(e)
                request_data["success"] = False
            
            finally:
                # Update global metrics
                self.total_requests += 1
                
                # Calculate running average
                if metrics.processing_time:
                    self.average_response_time = (
                        (self.average_response_time * (self.total_requests - 1) + metrics.processing_time) 
                        / self.total_requests
                    )
                
                # Move to completed
                self.completed_requests.append(metrics)
                del self.active_requests[request_id]
                
                # Keep only last 1000 completed requests
                if len(self.completed_requests) > 1000:
                    self.completed_requests = self.completed_requests[-1000:]
    
    async def submit_request(self, agent: Agent, user_input: str) -> str:
        """Submit request v√† ch·ªù k·∫øt qu·∫£"""
        
        request_id = f"req_{int(time.time() * 1000)}_{len(self.active_requests)}"
        
        # T·∫°o request data v·ªõi callback mechanism
        request_data = {
            "id": request_id,
            "agent": agent,
            "input": user_input,
            "future": asyncio.Future()
        }
        
        # Add to queue
        await self.request_queue.put(request_data)
        
        # Wait for completion (polling approach)
        while request_id in self.active_requests or request_data.get("result") is None:
            if request_data.get("success") is not None:  # Completed
                break
            await asyncio.sleep(0.1)  # Poll every 100ms
        
        if request_data.get("success"):
            return request_data["result"]
        else:
            raise Exception(request_data.get("error", "Unknown error"))
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ performance"""
        
        success_rate = (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0
        
        # Recent performance (last 100 requests)
        recent_requests = self.completed_requests[-100:]
        recent_avg_time = sum(r.processing_time for r in recent_requests if r.processing_time) / len(recent_requests) if recent_requests else 0
        
        return {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "success_rate": success_rate,
            "average_response_time": self.average_response_time,
            "recent_average_response_time": recent_avg_time,
            "active_requests": len(self.active_requests),
            "queue_size": self.request_queue.qsize(),
            "max_concurrent": self.max_concurrent
        }
    
    async def shutdown(self):
        """Graceful shutdown"""
        print("üõë Shutting down request processor...")
        
        # Stop workers
        for _ in self.workers:
            await self.request_queue.put(None)  # Shutdown signal
        
        # Wait for workers to finish
        await asyncio.gather(*self.workers, return_exceptions=True)
        
        print("‚úÖ Request processor shutdown complete")

# Load testing system
class LoadTester:
    """C√¥ng c·ª• load testing cho agents"""
    
    def __init__(self, processor: HighPerformanceRequestProcessor):
        self.processor = processor
    
    async def run_load_test(
        self, 
        agent: Agent, 
        test_queries: List[str], 
        concurrent_users: int = 10,
        requests_per_user: int = 5
    ) -> Dict[str, Any]:
        """Ch·∫°y load test v·ªõi concurrent users"""
        
        print(f"üöÄ Starting load test:")
        print(f"   ‚Ä¢ Concurrent users: {concurrent_users}")
        print(f"   ‚Ä¢ Requests per user: {requests_per_user}")
        print(f"   ‚Ä¢ Total requests: {concurrent_users * requests_per_user}")
        
        start_time = time.time()
        
        # T·∫°o tasks cho concurrent users
        user_tasks = []
        
        for user_id in range(concurrent_users):
            user_task = self._simulate_user_requests(
                agent, test_queries, requests_per_user, f"user_{user_id}"
            )
            user_tasks.append(user_task)
        
        # Ch·∫°y t·∫•t c·∫£ user tasks ƒë·ªìng th·ªùi
        user_results = await asyncio.gather(*user_tasks, return_exceptions=True)
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        # T·ªïng h·ª£p k·∫øt qu·∫£
        total_requests = 0
        successful_requests = 0
        
        for result in user_results:
            if isinstance(result, dict):
                total_requests += result["requests"]
                successful_requests += result["successful"]
        
        # Performance stats
        final_stats = self.processor.get_performance_stats()
        
        return {
            "load_test_summary": {
                "concurrent_users": concurrent_users,
                "requests_per_user": requests_per_user,
                "total_duration": total_duration,
                "requests_per_second": total_requests / total_duration,
                "success_rate": (successful_requests / total_requests * 100) if total_requests > 0 else 0
            },
            "performance_stats": final_stats,
            "individual_user_results": [r for r in user_results if isinstance(r, dict)]
        }
    
    async def _simulate_user_requests(
        self, 
        agent: Agent, 
        queries: List[str], 
        num_requests: int, 
        user_id: str
    ) -> Dict[str, Any]:
        """M√¥ ph·ªèng requests c·ªßa m·ªôt user"""
        
        import random
        
        successful = 0
        failed = 0
        response_times = []
        
        for i in range(num_requests):
            try:
                # Random query
                query = random.choice(queries)
                
                # Measure response time
                start = time.time()
                result = await self.processor.submit_request(agent, query)
                end = time.time()
                
                response_times.append(end - start)
                successful += 1
                
                # Random delay gi·ªØa requests (0.1-1s)
                await asyncio.sleep(random.uniform(0.1, 1.0))
                
            except Exception as e:
                failed += 1
                print(f"‚ùå {user_id} request {i+1} failed: {str(e)}")
        
        return {
            "user_id": user_id,
            "requests": num_requests,
            "successful": successful,
            "failed": failed,
            "avg_response_time": sum(response_times) / len(response_times) if response_times else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0
        }

# Demo performance optimization
async def demo_performance_optimization():
    """Demo h·ªá th·ªëng performance optimization"""
    
    print("‚ö° **Performance Optimization Demo**\n")
    
    # Setup high-performance processor
    processor = HighPerformanceRequestProcessor(max_concurrent=20)
    
    # T·∫°o test agent
    test_agent = Agent(
        name="Performance Test Agent",
        instructions="""
        B·∫°n l√† m·ªôt AI assistant ƒë∆∞·ª£c t·ªëi ∆∞u cho performance testing.
        
        Quy t·∫Øc ph·∫£n h·ªìi:
        - Tr·∫£ l·ªùi ng·∫Øn g·ªçn v√† s√∫c t√≠ch
        - T·∫≠p trung v√†o th√¥ng tin quan tr·ªçng
        - Tr√°nh c√°c c√¢u vƒÉn d√†i d√≤ng
        - S·ª≠ d·ª•ng bullet points khi ph√π h·ª£p
        
        M·ª•c ti√™u: Cung c·∫•p th√¥ng tin h·ªØu √≠ch v·ªõi th·ªùi gian ph·∫£n h·ªìi t·ªëi ∆∞u.
        """,
        model="gpt-4o-mini",  # Model nhanh cho testing
        model_settings={"temperature": 0.3, "max_tokens": 200}
    )
    
    # Test queries
    test_queries = [
        "Machine learning l√† g√¨?",
        "L·ª£i √≠ch c·ªßa cloud computing",
        "C√°ch t·ªëi ∆∞u database performance",
        "Best practices cho API design",
        "S·ª± kh√°c bi·ªát gi·ªØa REST v√† GraphQL",
        "Microservices vs Monolith",
        "Docker container ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?",
        "CI/CD pipeline l√† g√¨?",
        "C√°ch secure m·ªôt web application",
        "Performance monitoring tools n√†o t·ªët?"
    ]
    
    # Ch·∫°y load test
    load_tester = LoadTester(processor)
    
    print("üî• B·∫Øt ƒë·∫ßu load test...")
    
    load_test_results = await load_tester.run_load_test(
        agent=test_agent,
        test_queries=test_queries,
        concurrent_users=8,
        requests_per_user=3
    )
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    summary = load_test_results["load_test_summary"]
    print(f"\nüìä **Load Test Results:**")
    print(f"   ‚Ä¢ Total Duration: {summary['total_duration']:.2f}s")
    print(f"   ‚Ä¢ Requests/Second: {summary['requests_per_second']:.2f}")
    print(f"   ‚Ä¢ Success Rate: {summary['success_rate']:.1f}%")
    
    perf_stats = load_test_results["performance_stats"]
    print(f"\n‚ö° **Performance Stats:**")
    print(f"   ‚Ä¢ Total Requests: {perf_stats['total_requests']}")
    print(f"   ‚Ä¢ Average Response Time: {perf_stats['average_response_time']:.3f}s")
    print(f"   ‚Ä¢ Recent Average: {perf_stats['recent_average_response_time']:.3f}s")
    print(f"   ‚Ä¢ Max Concurrent: {perf_stats['max_concurrent']}")
    
    # User performance breakdown
    user_results = load_test_results["individual_user_results"]
    print(f"\nüë• **Per-User Performance:**")
    for user_result in user_results[:5]:  # Show first 5 users
        print(f"   ‚Ä¢ {user_result['user_id']}: {user_result['successful']}/{user_result['requests']} success, avg {user_result['avg_response_time']:.3f}s")
    
    # Cleanup
    await processor.shutdown()

if __name__ == "__main__":
    import asyncio
    asyncio.run(demo_performance_optimization())
```

## Cost Optimization v√† Resource Management

### Intelligent Cost Control

```python
import time
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum

class CostTier(Enum):
    """C√°c m·ª©c gi√° kh√°c nhau cho different models"""
    BUDGET = "budget"      # gpt-4o-mini
    STANDARD = "standard"  # gpt-4o
    PREMIUM = "premium"    # gpt-4-turbo, o1

@dataclass
class ModelCostConfig:
    """C·∫•u h√¨nh cost cho t·ª´ng model"""
    model_name: str
    cost_per_1k_input_tokens: float
    cost_per_1k_output_tokens: float
    tier: CostTier
    performance_score: int  # 1-10, cao h∆°n = performance t·ªët h∆°n

class IntelligentCostManager:
    """Qu·∫£n l√Ω chi ph√≠ th√¥ng minh cho OpenAI API"""
    
    def __init__(self, daily_budget: float = 100.0):
        self.daily_budget = daily_budget
        self.current_spend = 0.0
        self.spend_history: List[Dict[str, Any]] = []
        self.last_reset = datetime.now().date()
        
        # Model cost configurations (gi√° t√≠nh theo $)
        self.model_costs = {
            "gpt-4o-mini": ModelCostConfig(
                model_name="gpt-4o-mini",
                cost_per_1k_input_tokens=0.00015,
                cost_per_1k_output_tokens=0.0006,
                tier=CostTier.BUDGET,
                performance_score=7
            ),
            "gpt-4o": ModelCostConfig(
                model_name="gpt-4o",
                cost_per_1k_input_tokens=0.0025,
                cost_per_1k_output_tokens=0.01,
                tier=CostTier.STANDARD,
                performance_score=9
            ),
            "gpt-4-turbo": ModelCostConfig(
                model_name="gpt-4-turbo",
                cost_per_1k_input_tokens=0.01,
                cost_per_1k_output_tokens=0.03,
                tier=CostTier.PREMIUM,
                performance_score=10
            )
        }
        
        # Thresholds cho intelligent switching
        self.cost_thresholds = {
            "warning": 0.7,   # 70% of budget
            "critical": 0.9,  # 90% of budget
            "emergency": 0.95 # 95% of budget
        }
    
    def _reset_daily_budget_if_needed(self):
        """Reset budget n·∫øu qua ng√†y m·ªõi"""
        today = datetime.now().date()
        
        if today > self.last_reset:
            print(f"üìÖ New day detected, resetting budget")
            print(f"   Yesterday's spend: ${self.current_spend:.4f}")
            
            # Archive yesterday's data
            self.spend_history.append({
                "date": self.last_reset.isoformat(),
                "total_spend": self.current_spend,
                "budget": self.daily_budget,
                "utilization": self.current_spend / self.daily_budget
            })
            
            # Reset for new day
            self.current_spend = 0.0
            self.last_reset = today
    
    def calculate_request_cost(
        self, 
        model: str, 
        input_tokens: int, 
        output_tokens: int
    ) -> float:
        """T√≠nh cost cho m·ªôt request c·ª• th·ªÉ"""
        
        if model not in self.model_costs:
            print(f"‚ö†Ô∏è Unknown model {model}, using default pricing")
            model = "gpt-4o"  # Default fallback
        
        config = self.model_costs[model]
        
        input_cost = (input_tokens / 1000) * config.cost_per_1k_input_tokens
        output_cost = (output_tokens / 1000) * config.cost_per_1k_output_tokens
        
        return input_cost + output_cost
    
    def recommend_model(
        self, 
        complexity_score: int,  # 1-10, cao h∆°n = ph·ª©c t·∫°p h∆°n
        priority: str = "balanced"  # "cost", "performance", "balanced"
    ) -> str:
        """Recommend model d·ª±a tr√™n complexity v√† priority"""
        
        self._reset_daily_budget_if_needed()
        
        # Check budget status
        budget_utilization = self.current_spend / self.daily_budget
        
        # Emergency mode - ch·ªâ d√πng model r·∫ª nh·∫•t
        if budget_utilization >= self.cost_thresholds["emergency"]:
            print(f"üö® Emergency mode: Budget {budget_utilization:.1%} used, forcing budget model")
            return "gpt-4o-mini"
        
        # Critical mode - prefer budget models
        elif budget_utilization >= self.cost_thresholds["critical"]:
            print(f"‚ö†Ô∏è Critical budget mode: {budget_utilization:.1%} used")
            if complexity_score <= 6:
                return "gpt-4o-mini"
            else:
                return "gpt-4o"  # Minimum acceptable for complex tasks
        
        # Warning mode - be more conservative
        elif budget_utilization >= self.cost_thresholds["warning"]:
            print(f"‚ö†Ô∏è Budget warning: {budget_utilization:.1%} used")
            if priority == "cost" or complexity_score <= 4:
                return "gpt-4o-mini"
            elif complexity_score <= 8:
                return "gpt-4o"
            else:
                return "gpt-4-turbo"
        
        # Normal mode - optimize based on priority
        else:
            if priority == "cost":
                return "gpt-4o-mini" if complexity_score <= 6 else "gpt-4o"
            elif priority == "performance":
                return "gpt-4-turbo" if complexity_score >= 7 else "gpt-4o"
            else:  # balanced
                if complexity_score <= 4:
                    return "gpt-4o-mini"
                elif complexity_score <= 8:
                    return "gpt-4o"
                else:
                    return "gpt-4-turbo"
    
    def record_usage(
        self, 
        model: str, 
        input_tokens: int, 
        output_tokens: int,
        request_metadata: Dict[str, Any] = None
    ):
        """Ghi nh·∫≠n usage v√† update budget tracking"""
        
        cost = self.calculate_request_cost(model, input_tokens, output_tokens)
        self.current_spend += cost
        
        # Log usage
        usage_record = {
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "cost": cost,
            "cumulative_spend": self.current_spend,
            "metadata": request_metadata or {}
        }
        
        print(f"üí∞ Usage recorded: {model} - ${cost:.4f} (Total today: ${self.current_spend:.4f})")
        
        return usage_record
    
    def get_budget_status(self) -> Dict[str, Any]:
        """L·∫•y tr·∫°ng th√°i budget hi·ªán t·∫°i"""
        
        self._reset_daily_budget_if_needed()
        
        utilization = self.current_spend / self.daily_budget
        remaining = self.daily_budget - self.current_spend
        
        # Determine status
        if utilization >= self.cost_thresholds["emergency"]:
            status = "emergency"
        elif utilization >= self.cost_thresholds["critical"]:
            status = "critical"
        elif utilization >= self.cost_thresholds["warning"]:
            status = "warning"
        else:
            status = "healthy"
        
        return {
            "date": self.last_reset.isoformat(),
            "daily_budget": self.daily_budget,
            "current_spend": self.current_spend,
            "remaining_budget": remaining,
            "utilization_percentage": utilization * 100,
            "status": status,
            "recommended_action": self._get_budget_recommendation(status, utilization)
        }
    
    def _get_budget_recommendation(self, status: str, utilization: float) -> str:
        """ƒê·ªÅ xu·∫•t h√†nh ƒë·ªông d·ª±a tr√™n budget status"""
        
        if status == "emergency":
            return "Switch to budget models only, consider increasing daily budget"
        elif status == "critical":
            return "Prefer budget models, monitor usage closely"
        elif status == "warning":
            return "Be more selective with premium models"
        else:
            return "Budget healthy, can use models as needed"
    
    def get_cost_analytics(self) -> Dict[str, Any]:
        """Ph√¢n t√≠ch chi ph√≠ v√† ƒë∆∞a ra insights"""
        
        if not self.spend_history:
            return {"message": "Insufficient historical data"}
        
        # Recent performance
        recent_days = self.spend_history[-7:] if len(self.spend_history) >= 7 else self.spend_history
        
        avg_daily_spend = sum(day["total_spend"] for day in recent_days) / len(recent_days)
        avg_utilization = sum(day["utilization"] for day in recent_days) / len(recent_days)
        
        # Trends
        if len(recent_days) >= 2:
            recent_trend = recent_days[-1]["total_spend"] - recent_days[-2]["total_spend"]
            trend_direction = "increasing" if recent_trend > 0 else "decreasing" if recent_trend < 0 else "stable"
        else:
            trend_direction = "insufficient_data"
        
        return {
            "analytics_period": f"Last {len(recent_days)} days",
            "average_daily_spend": avg_daily_spend,
            "average_utilization": avg_utilization * 100,
            "trend_direction": trend_direction,
            "total_historical_spend": sum(day["total_spend"] for day in self.spend_history),
            "budget_efficiency": "good" if avg_utilization < 0.8 else "needs_optimization",
            "recommendations": self._generate_cost_recommendations(avg_utilization, trend_direction)
        }
    
    def _generate_cost_recommendations(self, avg_utilization: float, trend: str) -> List[str]:
        """Generate cost optimization recommendations"""
        
        recommendations = []
        
        if avg_utilization > 0.9:
            recommendations.append("Consider increasing daily budget or optimizing model usage")
        
        if trend == "increasing":
            recommendations.append("Monitor increasing cost trend, review model selection strategy")
        
        if avg_utilization < 0.5:
            recommendations.append("Budget utilization is low, could afford higher performance models")
        
        recommendations.append("Regularly review model performance vs cost trade-offs")
        recommendations.append("Consider implementing request batching for similar queries")
        
        return recommendations

# Cost-optimized agent wrapper
class CostOptimizedAgent:
    """Agent wrapper v·ªõi intelligent cost optimization"""
    
    def __init__(self, base_agent: Agent, cost_manager: IntelligentCostManager):
        self.base_agent = base_agent
        self.cost_manager = cost_manager
        
    def _assess_query_complexity(self, query: str) -> int:
        """ƒê√°nh gi√° ƒë·ªô ph·ª©c t·∫°p c·ªßa query (1-10)"""
        
        complexity_indicators = {
            "simple_keywords": ["g√¨ l√†", "l√† g√¨", "nghƒ©a l√†", "how to", "what is"],
            "complex_keywords": ["ph√¢n t√≠ch", "so s√°nh", "ƒë√°nh gi√°", "analyze", "compare", "evaluate"],
            "very_complex_keywords": ["strategy", "chi·∫øn l∆∞·ª£c", "optimization", "t·ªëi ∆∞u", "comprehensive"]
        }
        
        query_lower = query.lower()
        
        # Base complexity t·ª´ length
        base_complexity = min(len(query) // 50 + 1, 5)  # 1-5 based on length
        
        # Adjust d·ª±a tr√™n keywords
        if any(keyword in query_lower for keyword in complexity_indicators["very_complex_keywords"]):
            complexity = max(base_complexity + 4, 8)  # 8-10
        elif any(keyword in query_lower for keyword in complexity_indicators["complex_keywords"]):
            complexity = max(base_complexity + 2, 6)  # 6-8
        elif any(keyword in query_lower for keyword in complexity_indicators["simple_keywords"]):
            complexity = min(base_complexity, 4)  # 1-4
        else:
            complexity = base_complexity
        
        return min(complexity, 10)
    
    async def run_cost_optimized(
        self, 
        query: str, 
        priority: str = "balanced"
    ) -> Dict[str, Any]:
        """Run agent v·ªõi cost optimization"""
        
        # Assess complexity
        complexity = self._assess_query_complexity(query)
        
        # Get recommended model
        recommended_model = self.cost_manager.recommend_model(complexity, priority)
        
        print(f"ü§ñ Query complexity: {complexity}/10")
        print(f"üí° Recommended model: {recommended_model}")
        
        # Update agent model
        original_model = self.base_agent.model
        self.base_agent.model = recommended_model
        
        try:
            # Run agent
            start_time = time.time()
            result = await Runner.run(self.base_agent, query)
            end_time = time.time()
            
            # Estimate token usage (rough approximation)
            input_tokens = len(query.split()) * 1.3  # Approximate tokens
            output_tokens = len(result.final_output.split()) * 1.3
            
            # Record usage
            usage_record = self.cost_manager.record_usage(
                model=recommended_model,
                input_tokens=int(input_tokens),
                output_tokens=int(output_tokens),
                request_metadata={
                    "query_complexity": complexity,
                    "priority": priority,
                    "response_time": end_time - start_time
                }
            )
            
            return {
                "success": True,
                "result": result.final_output,
                "model_used": recommended_model,
                "complexity_score": complexity,
                "cost_info": {
                    "estimated_cost": usage_record["cost"],
                    "input_tokens": usage_record["input_tokens"],
                    "output_tokens": usage_record["output_tokens"]
                },
                "budget_status": self.cost_manager.get_budget_status()
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model_used": recommended_model,
                "complexity_score": complexity
            }
        
        finally:
            # Restore original model
            self.base_agent.model = original_model

# Demo cost optimization
async def demo_cost_optimization():
    """Demo intelligent cost optimization"""
    
    print("üí∞ **Cost Optimization Demo**\n")
    
    # Setup cost manager v·ªõi budget nh·ªè ƒë·ªÉ demo
    cost_manager = IntelligentCostManager(daily_budget=5.0)  # $5/day for demo
    
    # T·∫°o base agent
    base_agent = Agent(
        name="Cost-Optimized Assistant",
        instructions="""
        B·∫°n l√† m·ªôt AI assistant ƒë∆∞·ª£c t·ªëi ∆∞u v·ªÅ cost v√† performance.
        
        Nguy√™n t·∫Øc:
        - Tr·∫£ l·ªùi ch√≠nh x√°c v√† h·ªØu √≠ch
        - T·ªëi ∆∞u ƒë·ªô d√†i ph·∫£n h·ªìi ph√π h·ª£p v·ªõi ƒë·ªô ph·ª©c t·∫°p c√¢u h·ªèi
        - ∆Øu ti√™n th√¥ng tin quan tr·ªçng nh·∫•t
        - Tr√°nh d√†i d√≤ng kh√¥ng c·∫ßn thi·∫øt
        """,
        model="gpt-4o"  # Default model
    )
    
    # Wrap v·ªõi cost optimization
    cost_optimized_agent = CostOptimizedAgent(base_agent, cost_manager)
    
    # Test queries v·ªõi ƒë·ªô ph·ª©c t·∫°p kh√°c nhau
    test_scenarios = [
        {
            "query": "Python l√† g√¨?",
            "priority": "cost",
            "expected_complexity": "low"
        },
        {
            "query": "So s√°nh performance gi·ªØa React v√† Vue.js, ph√¢n t√≠ch ∆∞u nh∆∞·ª£c ƒëi·ªÉm c·ªßa t·ª´ng framework",
            "priority": "balanced", 
            "expected_complexity": "medium"
        },
        {
            "query": "X√¢y d·ª±ng chi·∫øn l∆∞·ª£c comprehensive ƒë·ªÉ optimize database performance cho enterprise application v·ªõi millions of users",
            "priority": "performance",
            "expected_complexity": "high"
        },
        {
            "query": "C√°ch install Docker?",
            "priority": "cost",
            "expected_complexity": "low"
        }
    ]
    
    total_cost = 0.0
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"üéØ **Test {i}: {scenario['expected_complexity'].title()} Complexity**")
        print(f"üìù Query: {scenario['query'][:80]}...")
        print(f"üéñÔ∏è Priority: {scenario['priority']}")
        
        result = await cost_optimized_agent.run_cost_optimized(
            scenario["query"],
            scenario["priority"]
        )
        
        if result["success"]:
            cost_info = result["cost_info"]
            total_cost += cost_info["estimated_cost"]
            
            print(f"‚úÖ Model: {result['model_used']}")
            print(f"üí∞ Cost: ${cost_info['estimated_cost']:.4f}")
            print(f"üìä Tokens: {cost_info['input_tokens']:.0f} in, {cost_info['output_tokens']:.0f} out")
            print(f"üéØ Response: {result['result'][:150]}...")
            
            # Budget status
            budget_status = result["budget_status"]
            print(f"üí≥ Budget: ${budget_status['current_spend']:.4f}/${budget_status['daily_budget']:.2f} ({budget_status['utilization_percentage']:.1f}%)")
            
        else:
            print(f"‚ùå Error: {result['error']}")
        
        print("-" * 80 + "\n")
    
    # Final cost analytics
    analytics = cost_manager.get_cost_analytics()
    
    print("üìà **Cost Analytics:**")
    if "message" not in analytics:
        print(f"üíµ Total Demo Cost: ${total_cost:.4f}")
        print(f"üìä Average Daily Spend: ${analytics['average_daily_spend']:.4f}")
        print(f"üìà Budget Efficiency: {analytics['budget_efficiency']}")
        
        print(f"\nüí° **Recommendations:**")
        for rec in analytics["recommendations"]:
            print(f"   ‚Ä¢ {rec}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(demo_cost_optimization())
```

## Security v√† Compliance

### Production Security Framework

```python
import hashlib
import secrets
import jwt
from typing import Dict, Any, List, Optional, Set
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import re

class SecurityLevel(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class SecurityPolicy:
    """Ch√≠nh s√°ch b·∫£o m·∫≠t cho agents"""
    max_input_length: int = 10000
    allowed_file_types: Set[str] = None
    rate_limit_per_user: int = 100  # requests per hour
    session_timeout_minutes: int = 30
    require_authentication: bool = True
    log_all_interactions: bool = True
    content_filtering_enabled: bool = True
    pii_detection_enabled: bool = True
    
    def __post_init__(self):
        if self.allowed_file_types is None:
            self.allowed_file_types = {'.txt', '.pdf', '.doc', '.docx'}

class ProductionSecurityManager:
    """Qu·∫£n l√Ω b·∫£o m·∫≠t cho production environment"""
    
    def __init__(self, secret_key: str, security_level: SecurityLevel = SecurityLevel.HIGH):
        self.secret_key = secret_key
        self.security_level = security_level
        self.security_policy = self._create_security_policy()
        
        # Tracking security events
        self.security_events: List[Dict[str, Any]] = []
        self.blocked_ips: Set[str] = set()
        self.rate_limits: Dict[str, List[datetime]] = {}
        
        # PII patterns
        self.pii_patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'(\+84|0)[0-9]{9,10}',
            'credit_card': r'\b(?:\d{4}[-\s]?){3}\d{4}\b',
            'ssn': r'\b\d{3}-?\d{2}-?\d{4}\b'
        }
        
        print(f"üîê Security Manager initialized with {security_level.value} security level")
    
    def _create_security_policy(self) -> SecurityPolicy:
        """T·∫°o security policy d·ª±a tr√™n security level"""
        
        if self.security_level == SecurityLevel.CRITICAL:
            return SecurityPolicy(
                max_input_length=5000,
                rate_limit_per_user=50,
                session_timeout_minutes=15,
                require_authentication=True,
                log_all_interactions=True,
                content_filtering_enabled=True,
                pii_detection_enabled=True
            )
        elif self.security_level == SecurityLevel.HIGH:
            return SecurityPolicy(
                max_input_length=8000,
                rate_limit_per_user=100,
                session_timeout_minutes=30,
                require_authentication=True,
                log_all_interactions=True,
                content_filtering_enabled=True,
                pii_detection_enabled=True
            )
        elif self.security_level == SecurityLevel.MEDIUM:
            return SecurityPolicy(
                max_input_length=10000,
                rate_limit_per_user=200,
                session_timeout_minutes=60,
                require_authentication=True,
                log_all_interactions=True,
                content_filtering_enabled=True,
                pii_detection_enabled=False
            )
        else:  # LOW
            return SecurityPolicy(
                max_input_length=15000,
                rate_limit_per_user=500,
                session_timeout_minutes=120,
                require_authentication=False,
                log_all_interactions=False,
                content_filtering_enabled=False,
                pii_detection_enabled=False
            )
    
    def generate_secure_token(self, user_id: str, permissions: List[str]) -> str:
        """T·∫°o secure JWT token"""
        
        payload = {
            'user_id': user_id,
            'permissions': permissions,
            'iat': datetime.utcnow(),
            'exp': datetime.utcnow() + timedelta(hours=24),
            'nonce': secrets.token_hex(16)
        }
        
        token = jwt.encode(payload, self.secret_key, algorithm='HS256')
        
        # Log token generation
        self._log_security_event(
            event_type="token_generated",
            user_id=user_id,
            details={"permissions": permissions}
        )
        
        return token
    
    def validate_token(self, token: str) -> Optional[Dict[str, Any]]:
        """Validate JWT token"""
        
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            
            # Check if token is not expired
            if datetime.utcnow() > datetime.fromisoformat(payload['exp'].replace('Z', '+00:00')):
                self._log_security_event(
                    event_type="token_expired",
                    user_id=payload.get('user_id'),
                    details={"token_hash": hashlib.sha256(token.encode()).hexdigest()[:16]}
                )
                return None
            
            return payload
            
        except jwt.InvalidTokenError as e:
            self._log_security_event(
                event_type="invalid_token",
                details={"error": str(e), "token_hash": hashlib.sha256(token.encode()).hexdigest()[:16]}
            )
            return None
    
    def check_rate_limit(self, user_id: str, ip_address: str) -> bool:
        """Ki·ªÉm tra rate limiting"""
        
        if ip_address in self.blocked_ips:
            self._log_security_event(
                event_type="blocked_ip_access",
                user_id=user_id,
                details={"ip": ip_address}
            )
            return False
        
        now = datetime.now()
        hour_ago = now - timedelta(hours=1)
        
        # Clean old requests
        if user_id in self.rate_limits:
            self.rate_limits[user_id] = [
                req_time for req_time in self.rate_limits[user_id]
                if req_time > hour_ago
            ]
        else:
            self.rate_limits[user_id] = []
        
        # Check rate limit
        current_requests = len(self.rate_limits[user_id])
        
        if current_requests >= self.security_policy.rate_limit_per_user:
            self._log_security_event(
                event_type="rate_limit_exceeded",
                user_id=user_id,
                details={"requests_in_hour": current_requests, "limit": self.security_policy.rate_limit_per_user}
            )
            return False
        
        # Record this request
        self.rate_limits[user_id].append(now)
        return True
    
    def validate_input(self, user_input: str, user_id: str) -> Dict[str, Any]:
        """Validate user input cho security threats"""
        
        validation_result = {
            "valid": True,
            "issues": [],
            "risk_level": "low",
            "sanitized_input": user_input
        }
        
        # Check input length
        if len(user_input) > self.security_policy.max_input_length:
            validation_result["valid"] = False
            validation_result["issues"].append(f"Input too long: {len(user_input)} > {self.security_policy.max_input_length}")
            validation_result["risk_level"] = "medium"
        
        # Check for potential injection attacks
        injection_patterns = [
            r'<script[^>]*>.*?</script>',  # XSS
            r'javascript:',
            r'on\w+\s*=',  # Event handlers
            r'union\s+select',  # SQL injection
            r'drop\s+table',
            r'insert\s+into',
            r'delete\s+from'
        ]
        
        for pattern in injection_patterns:
            if re.search(pattern, user_input, re.IGNORECASE):
                validation_result["valid"] = False
                validation_result["issues"].append(f"Potential injection attack detected: {pattern}")
                validation_result["risk_level"] = "high"
        
        # PII detection
        if self.security_policy.pii_detection_enabled:
            pii_found = self._detect_pii(user_input)
            if pii_found:
                validation_result["issues"].append(f"PII detected: {', '.join(pii_found.keys())}")
                validation_result["risk_level"] = "medium"
                
                # Sanitize PII
                sanitized = user_input
                for pii_type, matches in pii_found.items():
                    for match in matches:
                        sanitized = sanitized.replace(match, f"[{pii_type.upper()}_REDACTED]")
                validation_result["sanitized_input"] = sanitized
        
        # Content filtering
        if self.security_policy.content_filtering_enabled:
            if self._contains_inappropriate_content(user_input):
                validation_result["valid"] = False
                validation_result["issues"].append("Inappropriate content detected")
                validation_result["risk_level"] = "high"
        
        # Log security validation
        if not validation_result["valid"] or validation_result["issues"]:
            self._log_security_event(
                event_type="input_validation_failed",
                user_id=user_id,
                details={
                    "issues": validation_result["issues"],
                    "risk_level": validation_result["risk_level"],
                    "input_length": len(user_input)
                }
            )
        
        return validation_result
    
    def _detect_pii(self, text: str) -> Dict[str, List[str]]:
        """Ph√°t hi·ªán PII trong text"""
        
        pii_found = {}
        
        for pii_type, pattern in self.pii_patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                pii_found[pii_type] = matches
        
        return pii_found
    
    def _contains_inappropriate_content(self, text: str) -> bool:
        """Ki·ªÉm tra inappropriate content"""
        
        inappropriate_keywords = [
            'hack', 'exploit', 'malware', 'phishing',
            'illegal', 'fraud', 'scam'
        ]
        
        text_lower = text.lower()
        return any(keyword in text_lower for keyword in inappropriate_keywords)
    
    def _log_security_event(
        self, 
        event_type: str, 
        user_id: str = None, 
        details: Dict[str, Any] = None
    ):
        """Log security events"""
        
        event = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "user_id": user_id,
            "details": details or {},
            "security_level": self.security_level.value
        }
        
        self.security_events.append(event)
        
        # Keep only last 1000 events
        if len(self.security_events) > 1000:
            self.security_events = self.security_events[-1000:]
        
        # Print critical events
        if event_type in ["blocked_ip_access", "rate_limit_exceeded", "input_validation_failed"]:
            print(f"üö® Security Event: {event_type} - User: {user_id}")
    
    def get_security_report(self) -> Dict[str, Any]:
        """T·∫°o b√°o c√°o b·∫£o m·∫≠t"""
        
        if not self.security_events:
            return {"message": "No security events recorded"}
        
        # Event statistics
        event_types = {}
        for event in self.security_events:
            event_type = event["event_type"]
            event_types[event_type] = event_types.get(event_type, 0) + 1
        
        # Recent events (last 24 hours)
        day_ago = datetime.now() - timedelta(hours=24)
        recent_events = [
            event for event in self.security_events
            if datetime.fromisoformat(event["timestamp"]) > day_ago
        ]
        
        # Risk assessment
        high_risk_events = [
            event for event in recent_events
            if event["event_type"] in ["blocked_ip_access", "rate_limit_exceeded", "input_validation_failed"]
        ]
        
        risk_level = "high" if len(high_risk_events) > 10 else "medium" if len(high_risk_events) > 3 else "low"
        
        return {
            "report_generated": datetime.now().isoformat(),
            "security_level": self.security_level.value,
            "total_events": len(self.security_events),
            "events_last_24h": len(recent_events),
            "event_type_breakdown": event_types,
            "current_risk_level": risk_level,
            "blocked_ips_count": len(self.blocked_ips),
            "active_rate_limits": len(self.rate_limits),
            "recent_high_risk_events": len(high_risk_events),
            "security_recommendations": self._generate_security_recommendations(risk_level, event_types)
        }
    
    def _generate_security_recommendations(
        self, 
        risk_level: str, 
        event_types: Dict[str, int]
    ) -> List[str]:
        """Generate security recommendations"""
        
        recommendations = []
        
        if risk_level == "high":
            recommendations.append("Immediate review of security events required")
            
        if event_types.get("rate_limit_exceeded", 0) > 5:
            recommendations.append("Consider implementing IP-based blocking for repeat offenders")
            
        if event_types.get("input_validation_failed", 0) > 10:
            recommendations.append("Review and strengthen input validation rules")
            
        if event_types.get("invalid_token", 0) > 3:
            recommendations.append("Monitor for potential token brute force attempts")
        
        recommendations.extend([
            "Regularly rotate security keys and tokens",
            "Monitor security events dashboard daily",
            "Keep security policies updated with latest threats",
            "Conduct periodic security audits"
        ])
        
        return recommendations

# Secure agent wrapper
class SecureAgent:
    """Agent wrapper v·ªõi comprehensive security"""
    
    def __init__(self, agent: Agent, security_manager: ProductionSecurityManager):
        self.agent = agent
        self.security_manager = security_manager
        
    async def secure_run(
        self, 
        user_input: str, 
        user_id: str,
        auth_token: str,
        ip_address: str = "127.0.0.1"
    ) -> Dict[str, Any]:
        """Run agent v·ªõi full security checks"""
        
        # 1. Token validation
        if self.security_manager.security_policy.require_authentication:
            token_payload = self.security_manager.validate_token(auth_token)
            if not token_payload:
                return {
                    "success": False,
                    "error": "Invalid or expired authentication token",
                    "error_code": "AUTH_FAILED"
                }
            
            # Check if user_id matches token
            if token_payload.get("user_id") != user_id:
                return {
                    "success": False,
                    "error": "User ID mismatch",
                    "error_code": "AUTH_MISMATCH"
                }
        
        # 2. Rate limiting
        if not self.security_manager.check_rate_limit(user_id, ip_address):
            return {
                "success": False,
                "error": "Rate limit exceeded",
                "error_code": "RATE_LIMIT"
            }
        
        # 3. Input validation
        validation_result = self.security_manager.validate_input(user_input, user_id)
        
        if not validation_result["valid"]:
            return {
                "success": False,
                "error": "Input validation failed",
                "error_code": "INVALID_INPUT",
                "validation_issues": validation_result["issues"]
            }
        
        # 4. Run agent v·ªõi sanitized input
        try:
            result = await Runner.run(self.agent, validation_result["sanitized_input"])
            
            # Log successful interaction
            if self.security_manager.security_policy.log_all_interactions:
                self.security_manager._log_security_event(
                    event_type="agent_interaction_success",
                    user_id=user_id,
                    details={
                        "input_length": len(user_input),
                        "output_length": len(result.final_output),
                        "sanitized": validation_result["sanitized_input"] != user_input
                    }
                )
            
            return {
                "success": True,
                "result": result.final_output,
                "security_info": {
                    "input_sanitized": validation_result["sanitized_input"] != user_input,
                    "risk_level": validation_result["risk_level"]
                }
            }
            
        except Exception as e:
            # Log error
            self.security_manager._log_security_event(
                event_type="agent_execution_error",
                user_id=user_id,
                details={"error": str(e)}
            )
            
            return {
                "success": False,
                "error": "Agent execution failed",
                "error_code": "EXECUTION_ERROR"
            }

# Demo production security
async def demo_production_security():
    """Demo comprehensive production security"""
    
    print("üîê **Production Security Demo**\n")
    
    # Setup security manager
    security_manager = ProductionSecurityManager(
        secret_key="production_secret_key_2025",
        security_level=SecurityLevel.HIGH
    )
    
    # T·∫°o secure agent
    base_agent = Agent(
        name="Secure Production Agent",
        instructions="""
        B·∫°n l√† m·ªôt AI assistant ƒë∆∞·ª£c tri·ªÉn khai trong m√¥i tr∆∞·ªùng production b·∫£o m·∫≠t cao.
        
        Nguy√™n t·∫Øc b·∫£o m·∫≠t:
        - Kh√¥ng bao gi·ªù ti·∫øt l·ªô th√¥ng tin nh·∫°y c·∫£m
        - T·ª´ ch·ªëi c√°c y√™u c·∫ßu c√≥ th·ªÉ g√¢y h·∫°i
        - B√°o c√°o c√°c ho·∫°t ƒë·ªông ƒë√°ng ng·ªù
        - Tu√¢n th·ªß nghi√™m ng·∫∑t c√°c ch√≠nh s√°ch b·∫£o m·∫≠t
        
        Phong c√°ch ph·∫£n h·ªìi:
        - Chuy√™n nghi·ªáp v√† c·∫©n th·∫≠n
        - Minh b·∫°ch v·ªÅ gi·ªõi h·∫°n b·∫£o m·∫≠t
        - H∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng s·ª≠ d·ª•ng an to√†n
        """
    )
    
    secure_agent = SecureAgent(base_agent, security_manager)
    
    # Generate token cho test user
    test_user_id = "user_12345"
    auth_token = security_manager.generate_secure_token(
        user_id=test_user_id,
        permissions=["chat", "query"]
    )
    
    print(f"üé´ Generated auth token for {test_user_id}")
    
    # Test scenarios
    security_test_cases = [
        {
            "name": "Normal Query",
            "input": "Gi·∫£i th√≠ch machine learning c∆° b·∫£n",
            "should_succeed": True
        },
        {
            "name": "PII in Input",
            "input": "T√¥i t√™n Nguy·ªÖn VƒÉn An, email an@company.com, SƒêT 0901234567. H·ªèi v·ªÅ AI.",
            "should_succeed": True  # S·∫Ω sanitize PII
        },
        {
            "name": "Potential XSS Attack",
            "input": "<script>alert('hack')</script> Explain JavaScript",
            "should_succeed": False
        },
        {
            "name": "SQL Injection Attempt",
            "input": "'; DROP TABLE users; -- Explain databases",
            "should_succeed": False
        },
        {
            "name": "Very Long Input",
            "input": ("A" * 12000) + " What is AI?",  # V∆∞·ª£t qu√° limit
            "should_succeed": False
        }
    ]
    
    for i, test_case in enumerate(security_test_cases, 1):
        print(f"üß™ **Test {i}: {test_case['name']}**")
        
        result = await secure_agent.secure_run(
            user_input=test_case["input"],
            user_id=test_user_id,
            auth_token=auth_token,
            ip_address="192.168.1.100"
        )
        
        success_expected = test_case["should_succeed"]
        actual_success = result["success"]
        
        if actual_success == success_expected:
            status = "‚úÖ PASS"
        else:
            status = "‚ùå FAIL"
        
        print(f"   {status} - Expected: {success_expected}, Got: {actual_success}")
        
        if result["success"]:
            print(f"   üìù Response: {result['result'][:100]}...")
            if result.get("security_info", {}).get("input_sanitized"):
                print(f"   üßπ Input was sanitized for security")
        else:
            print(f"   üö´ Blocked: {result['error']} ({result.get('error_code')})")
        
        print()
    
    # Test rate limiting
    print("üö¶ **Testing Rate Limiting**")
    
    # Make multiple requests to trigger rate limit
    for i in range(5):
        result = await secure_agent.secure_run(
            user_input=f"Test request {i+1}",
            user_id=test_user_id,
            auth_token=auth_token,
            ip_address="192.168.1.100"
        )
        
        if result["success"]:
            print(f"   ‚úÖ Request {i+1}: Success")
        else:
            print(f"   üö´ Request {i+1}: {result['error']}")
    
    # Security report
    print("\nüìä **Security Report**")
    
    security_report = security_manager.get_security_report()
    
    print(f"üîê Security Level: {security_report['security_level']}")
    print(f"üìà Total Events: {security_report['total_events']}")
    print(f"‚è∞ Events (24h): {security_report['events_last_24h']}")
    print(f"üö® Risk Level: {security_report['current_risk_level']}")
    
    print(f"\nüìã **Event Breakdown:**")
    for event_type, count in security_report['event_type_breakdown'].items():
        print(f"   ‚Ä¢ {event_type}: {count}")
    
    print(f"\nüí° **Security Recommendations:**")
    for rec in security_report['security_recommendations'][:5]:
        print(f"   ‚Ä¢ {rec}")

if __name__ == "__main__":
    from agents import Runner
    import asyncio
    asyncio.run(demo_production_security())
```

## Nh·ªØng ƒêi·ªÅu C·∫ßn Bi·∫øt Khi ƒê∆∞a V√†o S·∫£n Xu·∫•t

### Ki·∫øn Th·ª©c C·ªët L√µi

‚úÖ **Environment management** - Ph√¢n chia r√µ r√†ng dev, staging v√† production  
‚úÖ **Performance optimization** - Request processing v·ªõi high concurrency  
‚úÖ **Cost management** - Intelligent model selection d·ª±a tr√™n complexity  
‚úÖ **Security framework** - Authentication, validation v√† monitoring to√†n di·ªán  
‚úÖ **Monitoring v√† alerting** - Theo d√µi li√™n t·ª•c ƒë·ªÉ ph√°t hi·ªán v·∫•n ƒë·ªÅ s·ªõm  

### Kinh Nghi·ªám T·ª´ Th·ª±c T·∫ø

üéØ **V·ªÅ Tr·∫£i Nghi·ªám Ng∆∞·ªùi D√πng:**
- Lu√¥n prioritize response time v√† availability
- Implement graceful degradation khi h·ªá th·ªëng qu√° t·∫£i
- Cung c·∫•p feedback r√µ r√†ng khi c√≥ l·ªói x·∫£y ra
- Design cho mobile-first n·∫øu c√≥ nhi·ªÅu user mobile
- Test thoroughly tr√™n c√°c devices v√† browsers kh√°c nhau

‚ö° **V·ªÅ Hi·ªáu Su·∫•t:**
- Monitor response time nh∆∞ metric quan tr·ªçng nh·∫•t
- Implement caching ·ªü nhi·ªÅu layers kh√°c nhau
- Use connection pooling ƒë·ªÉ optimize database connections
- Consider CDN cho static assets v√† responses
- Load test v·ªõi realistic traffic patterns

üîß **V·ªÅ Tri·ªÉn Khai:**
- Automate deployment process ho√†n to√†n
- Implement blue-green deployment ƒë·ªÉ minimize downtime
- Have rollback strategy s·∫µn s√†ng
- Monitor system health ngay sau m·ªói deployment
- Keep deployment logs ƒë·ªÉ troubleshoot khi c·∫ßn

### H∆∞·ªõng D·∫´n Tri·ªÉn Khai Production

üìä **Thi·∫øt L·∫≠p Monitoring:**
- Track key metrics: response time, error rate, throughput
- Set up alerts cho c√°c thresholds quan tr·ªçng
- Monitor cost v√† usage patterns daily
- Implement health checks cho t·∫•t c·∫£ components
- Create dashboards cho different stakeholders

üîí **B·∫£o M·∫≠t Production:**
- Implement defense-in-depth strategy
- Regular security audits v√† penetration testing
- Keep all dependencies updated
- Monitor cho suspicious activities
- Have incident response plan ready

üí∞ **Qu·∫£n L√Ω Chi Ph√≠:**
- Set up budget alerts v√† automatic controls
- Monitor usage patterns ƒë·ªÉ optimize model selection
- Implement request batching khi c√≥ th·ªÉ
- Regular cost analysis v√† optimization
- Consider reserved instances cho predictable workloads

### Nh·ªØng Sai L·∫ßm Th∆∞·ªùng G·∫∑p

‚ùå **Thi·∫øu monitoring** ‚Üí Kh√¥ng bi·∫øt khi n√†o system c√≥ v·∫•n ƒë·ªÅ  
‚ùå **Kh√¥ng c√≥ backup plan** ‚Üí Kh√¥ng th·ªÉ recover khi c√≥ s·ª± c·ªë  
‚ùå **Over-engineering t·ª´ ƒë·∫ßu** ‚Üí Waste time v√† resources  
‚ùå **Ignore security** ‚Üí Vulnerabilities c√≥ th·ªÉ ƒë∆∞·ª£c exploit  
‚ùå **Kh√¥ng test v·ªõi real data** ‚Üí Surprise khi go-live  

### Chi·∫øn L∆∞·ª£c Scaling

**üèóÔ∏è Horizontal Scaling:**
- Design stateless services t·ª´ ƒë·∫ßu cho easy replication
- S·ª≠ d·ª•ng load balancers ƒë·ªÉ distribute traffic evenly
- Implement database sharding strategies khi single DB kh√¥ng ƒë·ªß
- Consider microservices architecture cho large systems
- Plan cho multi-region deployment ƒë·ªÉ serve global users

**üìà Vertical Scaling:**
- Monitor resource utilization patterns ƒë·ªÉ identify bottlenecks
- Upgrade hardware khi cost-effective v√† necessary
- Optimize memory usage v√† CPU utilization
- Consider GPU instances cho AI-intensive workloads
- Profile application performance ƒë·ªÉ identify optimization opportunities

### K·∫ø Ho·∫°ch Disaster Recovery

üö® **Chu·∫©n B·ªã Cho S·ª± C·ªë:**
- Document t·∫•t c·∫£ procedures v√† runbooks chi ti·∫øt
- Th·ª±c hi·ªán regular backup v√† recovery testing
- Maintain multiple communication channels
- Train team members v·ªÅ incident response procedures
- Keep updated emergency contact lists v√† escalation paths

üîÑ **Business Continuity:**
- Define clear RTO (Recovery Time Objective) v√† RPO (Recovery Point Objective)
- Implement redundancy ·ªü critical system components
- Have alternative service providers s·∫µn s√†ng
- Conduct regular disaster recovery drills
- Maintain updated incident response v√† communication plans

### T·ªëi ∆Øu Chi Ph√≠ Trong D√†i H·∫°n

üí° **Chi·∫øn L∆∞·ª£c Cost Optimization:**
- Analyze usage patterns ƒë·ªÉ predict v√† optimize costs
- Implement smart caching ƒë·ªÉ reduce unnecessary API calls
- S·ª≠ d·ª•ng cheaper models cho simple, routine queries
- Consider training custom models cho specific, high-volume use cases
- Regular review v√† cleanup unused resources v√† subscriptions

üìä **Cost Tracking:**
- Implement detailed cost attribution v√† tracking
- Track ROI c·ªßa different features v√† use cases
- Setup cost allocation tags cho different projects/departments
- Conduct regular cost review meetings v·ªõi stakeholders
- Forecast future costs based on growth projections v√† plans

### Chu·∫©n B·ªã Cho T∆∞∆°ng Lai

üîÆ **Technology Evolution:**
- Stay updated v·ªõi latest AI developments
- Plan cho model upgrades v√† migrations
- Consider emerging technologies nh∆∞ multimodal AI
- Invest in team training v√† development
- Build flexible architecture c√≥ th·ªÉ adapt

üå± **Business Growth:**
- Plan infrastructure scaling cho anticipated growth
- Consider international expansion requirements
- Prepare cho regulatory compliance changes
- Build partnerships v·ªõi technology vendors
- Invest in automation ƒë·ªÉ handle scale

### Checklist Cu·ªëi C√πng Tr∆∞·ªõc Khi Go-Live

**‚úÖ S·∫µn S√†ng K·ªπ Thu·∫≠t:**
- [ ] Load testing passed v·ªõi expected traffic volumes
- [ ] Security audit completed v√† all vulnerabilities addressed
- [ ] Monitoring v√† alerting systems ho√†n t·∫•t v√† tested
- [ ] Backup v√† recovery procedures tested successfully
- [ ] Performance benchmarks established v√† documented

**‚úÖ S·∫µn S√†ng V·∫≠n H√†nh:**
- [ ] Team training completed cho all relevant personnel
- [ ] Documentation updated v√† easily accessible
- [ ] Incident response procedures ready v√† tested
- [ ] Customer support processes established
- [ ] Communication plans prepared cho different scenarios

**‚úÖ S·∫µn S√†ng Business:**
- [ ] User acceptance testing passed v·ªõi real users
- [ ] Legal v√† compliance requirements fully met
- [ ] Marketing materials prepared cho launch
- [ ] Customer support team ready v·ªõi proper training
- [ ] Success metrics defined v√† tracking systems ready

---

*Ch√∫c m·ª´ng b·∫°n ƒë√£ ho√†n th√†nh h√†nh tr√¨nh kh√°m ph√° OpenAI Agents SDK! T·ª´ nh·ªØng b∆∞·ªõc ƒë·∫ßu ti√™n v·ªõi "Hello World" ƒë·∫øn vi·ªác tri·ªÉn khai production-grade systems, b·∫°n ƒë√£ trang b·ªã ƒë·∫ßy ƒë·ªß ki·∫øn th·ª©c ƒë·ªÉ x√¢y d·ª±ng nh·ªØng AI applications m·∫°nh m·∫Ω v√† ƒë√°ng tin c·∫≠y. H√£y √°p d·ª•ng nh·ªØng ki·∫øn th·ª©c n√†y v√†o projects th·ª±c t·∫ø v√† ti·∫øp t·ª•c h·ªçc h·ªèi t·ª´ community ƒë·ªÉ kh√¥ng ng·ª´ng c·∫£i thi·ªán skills c·ªßa m√¨nh.*